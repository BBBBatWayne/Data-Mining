{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 1.235128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "import math\n",
    "\n",
    "\n",
    "def gen_bias(bias,item):\n",
    "\treturn float(bias[item][0])/bias[item][1]\n",
    "\t\n",
    "def cosine_sim(user,item,user_map,item_map,bias):\n",
    "\ttotal = 0 \n",
    "\tscore = 0\n",
    "\tfor u in user_map[user]:\n",
    "\t\tcompare = set(item_map[item].keys()).intersection(item_map[u].keys())\n",
    "\t\tif len(compare) == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tup = 0 \n",
    "\t\tdown1 = 0\n",
    "\t\tdown2 = 0\n",
    "\t\tfor i in compare:\n",
    "\t\t\tr1 = item_map[u][i]\n",
    "\t\t\tr2 = item_map[item][i]\n",
    "\t\t\tup += r1*r2\n",
    "\t\t\tdown1 += pow(r1,2)\n",
    "\t\t\tdown2 += pow(r2,2)\n",
    "\t\tdown1 = math.sqrt(down1)\n",
    "\t\tdown2 = math.sqrt(down2)\n",
    "\t\tsim = float(up) / (down1*down2) \n",
    "\t\tscore += sim * (item_map[u][user]- gen_bias(bias,u))\n",
    "\t\ttotal = total + sim\n",
    "\ttry:\n",
    "\t\tfinal = float(score)/total + gen_bias(bias,user)\n",
    "\texcept ZeroDivisionError:\n",
    "\t\tfinal = 1\n",
    "\t### scaling\n",
    "\tif final > 5:\n",
    "\t\tfinal = 5\n",
    "\tif final < 0:\n",
    "\t\tfinal = 0\n",
    "\treturn final\n",
    "\t\n",
    "\t\n",
    "def pearson_sim(user,item,user_map,item_map,bias):\n",
    "\ttotal = 0 \n",
    "\tscore = 0\n",
    "\tfor u in item_map[item]:\n",
    "\t\tcompare = set(user_map[user].keys()).intersection(user_map[u].keys())\n",
    "\t\tif len(compare) == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tup = 0 \n",
    "\t\tdown1 = 0\n",
    "\t\tdown2 = 0\n",
    "\t\tfor i in compare:\n",
    "\t\t\tr1 = user_map[u][i] - float(bias[u][0])/bias[u][1]\n",
    "\t\t\tr2 = user_map[user][i] - float(bias[user][0])/bias[user][1]\n",
    "\t\t\tup += r1*r2\n",
    "\t\t\tdown1 += pow(r1,2)\n",
    "\t\t\tdown2 += pow(r2,2)\n",
    "\t\tif (down1==0) or (down2==0):\n",
    "\t\t\tcontinue\n",
    "\t\tdown1 = math.sqrt(down1)\n",
    "\t\tdown2 = math.sqrt(down2)\n",
    "\t\tsim = float(up) / (down1*down2)\n",
    "\t\tscore += sim * (user_map[u][item]- gen_bias(bias,u)) \n",
    "\t\ttotal = total + sim\n",
    "\tfinal = float(score)/total+ gen_bias(bias,user)\n",
    "\n",
    "\tif final > 5:\n",
    "\t\tfinal = 5\n",
    "\tif final < 0:\n",
    "\t\tfinal = 0\n",
    "\treturn final\t\n",
    "\n",
    "output = 'Output.txt'\n",
    "### construct the item_map and user_map\n",
    "item_map = {}\n",
    "user_map = {}\n",
    "bias = {}\n",
    "global_bias = 0\n",
    "global_count = 0\n",
    "with open('train_all_txt.txt','r') as f:\n",
    "\tfor line in f:\n",
    "\t\twords = line.split()\n",
    "\t\tuser = int(words[0])\n",
    "\t\titem = int(words[1])\n",
    "\t\trating = int(words[2])\n",
    "\t\tif user not in user_map.keys():\n",
    "\t\t\tuser_map[user] = set([item])\n",
    "\t\telse:\n",
    "\t\t\tuser_map[user].add(item)\n",
    "\t\tif item not in item_map.keys():\n",
    "\t\t\titem_map[item] = {}\n",
    "\t\t\titem_map[item][user] = rating\n",
    "\t\telse:\n",
    "\t\t\titem_map[item][user] = rating\n",
    "\t\t### construct user bias\n",
    "\t\tif item not in bias.keys():\n",
    "\t\t\tbias[item] = [rating,1]\n",
    "\t\telse:\n",
    "\t\t\tbias[item][0] += rating\n",
    "\t\t\tbias[item][1] += 1\n",
    "\t\t### global bias\n",
    "\t\tglobal_bias += rating\n",
    "\t\tglobal_count += 1\n",
    "global_bias = float(global_bias)/global_count\n",
    "\n",
    "\t\n",
    "# cosine similarity\t\n",
    "with open('testing.txt','r') as f:\n",
    "\twith open(output,'w') as g:\n",
    "\t\tcount = 0\n",
    "\t\tfor line in f:\n",
    "\t\t\twords = line.split()\n",
    "\t\t\tuser = int(words[0])\n",
    "\t\t\titem = int(words[1])\n",
    "\t\t\t\n",
    "\t\t\t### cold start item\n",
    "\t\t\tif item not in item_map.keys():\n",
    "\t\t\t\tg.write('%d %d %d\\n' %(user, item,  int(round(global_bias))))\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tpred = cosine_sim(user,item,user_map,item_map,bias)\n",
    "\t\t\t#pred = pearson_sim(user,item,user_map,item_map,bias)\n",
    "\t\t\tg.write('%d %d %d\\n' %(user, item,  int(round(pred))))\n",
    "\t\t\t#count += 1\n",
    "\t\t\t#if (count % 1000) == 0:\n",
    "\t\t\t#\tprint(count)\n",
    "\n",
    "### Calculate training RMSE\t\t\t\t\n",
    "with open('train_all_txt.txt','r') as f:\n",
    "\tcount = 0\n",
    "\trmse = 0 \n",
    "\tfor line in f:\n",
    "\t\twords = line.split()\n",
    "\t\tuser = int(words[0])\n",
    "\t\titem = int(words[1])\n",
    "\t\trating = int(words[2])\n",
    "\t\tpred = cosine_sim(user,item,user_map,item_map,bias)\n",
    "\t\trmse += pow(rating-pred,2)\n",
    "\t\tcount += 1\n",
    "print ('rmse: %f\\n' % math.sqrt(rmse/count))\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
